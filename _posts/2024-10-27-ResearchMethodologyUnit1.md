
#unit; #Reasearch
<H1> e-Portfolio Activity: Reflective Activity 1 – Ethics in Computing in the age of Generative AI < /H1>

<P>After reviewing the article and reading how different countries across the world deal with the generative AI revolution, discuss your views on the subject and recommend what you think could be a suitable course of action. You should justify your stance by also reviewing any papers included in this study or other relevant literature (additional links to industry have been provided as ‘Other Resources’ to the module). Your discussion should also highlight the impact your actions would have on applicable legal, social and professional issues. Please note that there is no right or wrong answer here, this exercise is to help you evaluate the legal, social ethical and professional issues that affect computing professionals in industry.
The word count is 1,000 for the reflection piece. You will have to include this in your e-portfolio, but you can submit it to your tutor for formative feedback before Week 12.</P>

<P>I agree that Ai ethics should take on as many view points as possible and not only of those countries that are developing Ai at the moment but even populations that may not currently have a say. We also need to consider what ethics actually means in different countries, and example given was that China are willing to collect data from their populous without any consent required, should this occur what stops them from doing even more unethical ventures to gain a competitive advance. This is something thus far that has not been discussed in the papers sampled. Competition and greed  are major factors that affect how communities, countries and people view ethics and even the law. </P>

<P>Issues and gaps that were raised in the methodology also did not mention competitiveness and the grey areas and even darker regions of non-ethical developers that would use AI technology for self interest and monetary gain. As we all are aware cybercriminals use alot of the literature posted to find gaps themselves and use it for personal gain. Although most law abiding citizens know better and as mentioned do research to contribute to the betterment of overall knowledge contribution.
A mitigation classification mentioned, although not meant as a mitigation but as a methodology but I think is possibly the mitigation requirements for organizations ,is possibly the use of Government regulations, self-regulations/ voluntary self commitment for private organisations and Recommendation documentation designed for suggested forms of governance and ethical principles to help guide organizations. </P>

<P>There were 17 aggregated values and principles that were repeated the most across  all the research of the articles from  Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance, (Correa . et al.2023), Some of these are  Accountability/liability refers to developers be compliant to regulatory bodies and be accountable for their actions. Beneficence/ non-maleficence comes from bioethics and medical ethics of which the principle is human welfare  first. Children and adolescent rights, must be protected. Dignity / human rights is an idea that all Ai ethics should have respect for human dignity and human rights.  Further ethical definition of Diversity/inclusion/pluralism/accessibility advocated that development and use of AI technology should be inclusive of gender, ethnicity, race, disability etc. The last option that I will list is truthfulness in which the idea is that people should not be deceived when interacting with AI services.
Just these six values mentioned of the 17 shows that AI ethics are placed in the hands of principles and ethical goodwill. We know from experience of hackers and other cybercriminals that this will not stop the unethical and criminal minded exploiting AI. I believe we need some sort of automated control of AI or a central regulatory body that reviews an AI before it is deployed.  Even an AI that reviews new AI technologies to ensure that the principles expressed and guidelines set are in fact ethical and non bias.</P>

<P>Limitations expressed in the article by Correa. 2023, based on the samples used is also what I believe would be missing in many AI requirements. The bias on languages represented is that all samples were probably in English and AI as with most programming languages are English based. This then begs the question ,are other language perspectives lost and would non first language English speakers interpret AI out in the same way or would cultural bias also become an issue based on countries that are English first language. Further bias limitations mentioned is publication bias , in which only certain guidelines were reviewed again this could also be expanded to language bias as to which language publications were reviewed. If ethical Al guidelines are only in English publications how would this reach non-English speaking countries. This I think can be assisted by AI technology that converts documents into different languages.  Political bias and viewpoints also comes into play when developing Ai ethics. Countries such as Russia and China are known to look the other way when if hackers within their boundaries hack / phish other countries, with the advent of AI this increases these criminal activities exponentially. </P>

